{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cube.api import Cube     \n",
    "cube=Cube(verbose=True)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from load_baseline_crf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Jobs_NYC_Postings_20231126.csv\")\n",
    "df = df.loc[:]\n",
    "df = df.dropna(subset=['Minimum Qual Requirements', 'Preferred Skills'], how='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.loc[:, ['Job ID', 'Minimum Qual Requirements', 'Preferred Skills']]\n",
    "target = target.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = ['', '¢', 'â', '*']\n",
    "def remove_special_character(text, dic):\n",
    "    s = ''\n",
    "    for word in text:\n",
    "        if word not in dic:\n",
    "            s += word\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606346</td>\n",
       "      <td>1. A masters degree from an accredited colleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>571361</td>\n",
       "      <td>At least six years of full-time satisfactory e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600579</td>\n",
       "      <td>1. A baccalaureate degree from an accredited c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569683</td>\n",
       "      <td>1. A baccalaureate degree from an accredited c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>614260</td>\n",
       "      <td>A four-year high school diploma or its educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>614585</td>\n",
       "      <td>nanCompletion of FEMA IS-100, 200, 700, and 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>616195</td>\n",
       "      <td>1.  For Assignment Level I (only physical, bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>611205</td>\n",
       "      <td>1.  For Assignment Level I (only physical, bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>602272</td>\n",
       "      <td>1. A masters degree from an accredited colleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>602875</td>\n",
       "      <td>1.  A baccalaureate degree from an accredited ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Job ID                                             skills\n",
       "0     606346  1. A masters degree from an accredited colleg...\n",
       "1     571361  At least six years of full-time satisfactory e...\n",
       "2     600579  1. A baccalaureate degree from an accredited c...\n",
       "3     569683  1. A baccalaureate degree from an accredited c...\n",
       "4     614260  A four-year high school diploma or its educati...\n",
       "...      ...                                                ...\n",
       "6181  614585  nanCompletion of FEMA IS-100, 200, 700, and 80...\n",
       "6182  616195  1.  For Assignment Level I (only physical, bio...\n",
       "6183  611205  1.  For Assignment Level I (only physical, bio...\n",
       "6184  602272  1. A masters degree from an accredited colleg...\n",
       "6185  602875  1.  A baccalaureate degree from an accredited ...\n",
       "\n",
       "[6181 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['Minimum Qual Requirements'] = target['Minimum Qual Requirements'].apply(lambda x : remove_special_character(x, dic))\n",
    "target['Preferred Skills'] = target['Preferred Skills'].apply(lambda x : remove_special_character(x, dic))\n",
    "target['skills'] = target['Minimum Qual Requirements'] + target['Preferred Skills']\n",
    "target = target.drop(columns = ['Minimum Qual Requirements', 'Preferred Skills'])\n",
    "target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Segmentation + boi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "cube.load(\"en\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boi(txt):\n",
    "    try:\n",
    "        txt = cube(txt)\n",
    "        sentence_num = 1\n",
    "        lemma, pos, sentence_number, tag = [], [], [], []\n",
    "        for sentence in txt.sentences:\n",
    "            for token in sentence.tokens:\n",
    "                for word in token.words:\n",
    "                    pos.append(word.xpos)\n",
    "                    lemma.append(word.lemma)\n",
    "                    sentence_number.append(sentence_num)\n",
    "                    tag.append('?')\n",
    "            sentence_num += 1\n",
    "    except:\n",
    "        sentence_num = 1\n",
    "        lemma, pos, sentence_number, tag = [], [], [], []\n",
    "        for s in nltk.sent_tokenize(txt):\n",
    "            pos_tagged_sentences = nltk.pos_tag(nltk.word_tokenize(s))\n",
    "            for item in pos_tagged_sentences:\n",
    "                pos.append(item[1])\n",
    "                lemma.append(item[0])\n",
    "                sentence_number.append(sentence_num)\n",
    "                tag.append('?')\n",
    "        sentence_num += 1\n",
    "                \n",
    "    df_pos = pd.DataFrame({'sentence_id': sentence_number,\n",
    "                           'word': lemma,\n",
    "                           'pos': pos,\n",
    "                           'tag': tag})\n",
    "\n",
    "    X_test = prepare_prompt(df_pos)\n",
    "    y_pred = crf.predict(X_test)\n",
    "        \n",
    "    boi_list = []\n",
    "    for l in y_pred:\n",
    "        boi_list += l\n",
    "    \n",
    "    df_pos['tag'] = boi_list\n",
    "    # only keeps the columns where tag not equals to O\n",
    "    \n",
    "    b, s, result = False, '', []\n",
    "    for row in df_pos.iterrows():\n",
    "        if row[1]['tag'][0] == 'B':\n",
    "            b = True\n",
    "            if row[1]['word'] != '.<UNK>' and row[1]['word'] != '<UNK>':\n",
    "                s += str(row[1]['word'])\n",
    "                s += ' '\n",
    "        elif b and row[1]['tag'][0] == 'I':\n",
    "            if row[1]['word'] != '.<UNK>' and row[1]['word'] != '<UNK>':\n",
    "                s += str(row[1]['word'])\n",
    "                s += ' '\n",
    "        else:\n",
    "            if b:\n",
    "                s = s[: -1]\n",
    "                result.append(s)\n",
    "            b = False\n",
    "            s = ''\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['Extracted_Skills'] = target['skills'].apply(lambda x : boi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv('result_quanliang.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
